{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook à utiliser pour faire le travail pratique # 3 sur l'analyse d'incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"c:\\Users\\taha\\Coding\\.venv\\Lib\\site-packages\\torch\\lib\\omptarget.sycl.wrap.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, f1_score\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistilBertTokenizer, DistilBertForTokenClassification, AdamW\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# from torch.utils.data import DataLoader, Dataset\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\taha\\Coding\\.venv\\Lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     logging,\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     50\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\taha\\Coding\\.venv\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\taha\\Coding\\.venv\\Lib\\site-packages\\transformers\\utils\\__init__.py:31\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     25\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     30\u001b[0m )\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     ContextManagers,\n\u001b[0;32m     33\u001b[0m     ExplicitEnum,\n\u001b[0;32m     34\u001b[0m     ModelOutput,\n\u001b[0;32m     35\u001b[0m     PaddingStrategy,\n\u001b[0;32m     36\u001b[0m     TensorType,\n\u001b[0;32m     37\u001b[0m     add_model_info_to_auto_map,\n\u001b[0;32m     38\u001b[0m     cached_property,\n\u001b[0;32m     39\u001b[0m     can_return_loss,\n\u001b[0;32m     40\u001b[0m     expand_dims,\n\u001b[0;32m     41\u001b[0m     find_labels,\n\u001b[0;32m     42\u001b[0m     flatten_dict,\n\u001b[0;32m     43\u001b[0m     infer_framework,\n\u001b[0;32m     44\u001b[0m     is_jax_tensor,\n\u001b[0;32m     45\u001b[0m     is_numpy_array,\n\u001b[0;32m     46\u001b[0m     is_tensor,\n\u001b[0;32m     47\u001b[0m     is_tf_symbolic_tensor,\n\u001b[0;32m     48\u001b[0m     is_tf_tensor,\n\u001b[0;32m     49\u001b[0m     is_torch_device,\n\u001b[0;32m     50\u001b[0m     is_torch_dtype,\n\u001b[0;32m     51\u001b[0m     is_torch_tensor,\n\u001b[0;32m     52\u001b[0m     reshape,\n\u001b[0;32m     53\u001b[0m     squeeze,\n\u001b[0;32m     54\u001b[0m     strtobool,\n\u001b[0;32m     55\u001b[0m     tensor_size,\n\u001b[0;32m     56\u001b[0m     to_numpy,\n\u001b[0;32m     57\u001b[0m     to_py_obj,\n\u001b[0;32m     58\u001b[0m     transpose,\n\u001b[0;32m     59\u001b[0m     working_or_temp_dir,\n\u001b[0;32m     60\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     62\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[0;32m     63\u001b[0m     DISABLE_TELEMETRY,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m     try_to_load_from_cache,\n\u001b[0;32m     91\u001b[0m )\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     93\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[0;32m     94\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m     torch_required,\n\u001b[0;32m    198\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\taha\\Coding\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:432\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_torch_pytree\u001b[39;00m\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_model_output_flatten\u001b[39m(output: ModelOutput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[Any], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_pytree.Context\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mvalues()), (\u001b[38;5;28mtype\u001b[39m(output), \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "File \u001b[1;32mc:\\Users\\taha\\Coding\\.venv\\Lib\\site-packages\\torch\\__init__.py:139\u001b[0m\n\u001b[0;32m    137\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    138\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 139\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    141\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"c:\\Users\\taha\\Coding\\.venv\\Lib\\site-packages\\torch\\lib\\omptarget.sycl.wrap.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from transformers import DistilBertTokenizer, DistilBertForTokenClassification, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ -----------\n",
      "aiobotocore              2.5.0\n",
      "aiohttp                  3.8.4\n",
      "aioitertools             0.11.0\n",
      "aiosignal                1.3.1\n",
      "altair                   5.0.1\n",
      "androguard               3.3.5\n",
      "annotated-types          0.6.0\n",
      "anyio                    3.6.2\n",
      "argon2-cffi              21.3.0\n",
      "argon2-cffi-bindings     21.2.0\n",
      "arrow                    1.2.3\n",
      "asn1crypto               1.5.1\n",
      "asttokens                2.2.1\n",
      "async-timeout            4.0.2\n",
      "attrs                    22.2.0\n",
      "backcall                 0.2.0\n",
      "beautifulsoup4           4.12.2\n",
      "bleach                   6.0.0\n",
      "blinker                  1.6.2\n",
      "blis                     0.7.11\n",
      "botocore                 1.29.76\n",
      "cachetools               5.3.1\n",
      "catalogue                2.0.10\n",
      "certifi                  2022.12.7\n",
      "cffi                     1.15.1\n",
      "charset-normalizer       3.1.0\n",
      "click                    8.1.3\n",
      "cloudpathlib             0.16.0\n",
      "colorama                 0.4.6\n",
      "comm                     0.1.3\n",
      "confection               0.1.3\n",
      "contourpy                1.0.7\n",
      "cycler                   0.11.0\n",
      "cymem                    2.0.8\n",
      "debugpy                  1.6.7\n",
      "decorator                5.1.1\n",
      "defusedxml               0.7.1\n",
      "et-xmlfile               1.1.0\n",
      "executing                1.2.0\n",
      "fastjsonschema           2.16.3\n",
      "filelock                 3.13.1\n",
      "Flask                    2.3.2\n",
      "fontawesomefree          6.5.1\n",
      "fonttools                4.39.4\n",
      "fqdn                     1.5.1\n",
      "frozenlist               1.3.3\n",
      "fsspec                   2023.12.2\n",
      "future                   0.18.3\n",
      "gensim                   4.3.2\n",
      "gitdb                    4.0.10\n",
      "GitPython                3.1.31\n",
      "htmlmin                  0.1.12\n",
      "huggingface-hub          0.19.4\n",
      "idna                     3.4\n",
      "ImageHash                4.3.1\n",
      "importlib-metadata       6.6.0\n",
      "intel-openmp             2024.0.0\n",
      "ipykernel                6.22.0\n",
      "ipython                  8.12.0\n",
      "ipython-genutils         0.2.0\n",
      "ipywidgets               8.0.6\n",
      "isoduration              20.11.0\n",
      "itsdangerous             2.1.2\n",
      "jedi                     0.18.2\n",
      "Jinja2                   3.1.2\n",
      "jmespath                 1.0.1\n",
      "joblib                   1.1.1\n",
      "jsonpointer              2.3\n",
      "jsonschema               4.17.3\n",
      "jupyter                  1.0.0\n",
      "jupyter_client           8.1.0\n",
      "jupyter-console          6.6.3\n",
      "jupyter_core             5.3.0\n",
      "jupyter-events           0.6.3\n",
      "jupyter_server           2.5.0\n",
      "jupyter_server_terminals 0.4.4\n",
      "jupyterlab-pygments      0.2.2\n",
      "jupyterlab-widgets       3.0.7\n",
      "kafka-python             2.0.2\n",
      "kiwisolver               1.4.4\n",
      "langcodes                3.3.0\n",
      "lxml                     4.9.2\n",
      "Markdown                 3.5.1\n",
      "markdown-it-py           2.2.0\n",
      "MarkupSafe               2.1.2\n",
      "matplotlib               3.7.1\n",
      "matplotlib-inline        0.1.6\n",
      "mdurl                    0.1.2\n",
      "missingno                0.5.2\n",
      "mistune                  2.0.5\n",
      "mpmath                   1.3.0\n",
      "multidict                6.0.4\n",
      "multimethod              1.10\n",
      "murmurhash               1.0.10\n",
      "nbclassic                1.0.0\n",
      "nbclient                 0.7.4\n",
      "nbconvert                7.4.0\n",
      "nbformat                 5.8.0\n",
      "nest-asyncio             1.5.6\n",
      "networkx                 3.1\n",
      "nltk                     3.8.1\n",
      "notebook                 6.5.4\n",
      "notebook_shim            0.2.3\n",
      "numpy                    1.25.2\n",
      "openpyxl                 3.1.2\n",
      "packaging                23.0\n",
      "pandas                   1.5.3\n",
      "pandas-profiling         3.2.0\n",
      "pandocfilters            1.5.0\n",
      "parso                    0.8.3\n",
      "phik                     0.12.3\n",
      "pickleshare              0.7.5\n",
      "Pillow                   9.5.0\n",
      "pip                      23.3.1\n",
      "platformdirs             3.2.0\n",
      "praw                     7.7.0\n",
      "prawcore                 2.3.0\n",
      "preshed                  3.0.9\n",
      "prometheus-client        0.16.0\n",
      "prompt-toolkit           3.0.38\n",
      "protobuf                 4.23.2\n",
      "psutil                   5.9.4\n",
      "pure-eval                0.2.2\n",
      "pyarrow                  12.0.0\n",
      "pycparser                2.21\n",
      "pydantic                 2.5.1\n",
      "pydantic_core            2.14.3\n",
      "pydeck                   0.8.1b0\n",
      "pydot                    1.4.2\n",
      "Pygments                 2.14.0\n",
      "Pympler                  1.0.1\n",
      "pyparsing                3.0.9\n",
      "pyrsistent               0.19.3\n",
      "python-dateutil          2.8.2\n",
      "python-json-logger       2.0.7\n",
      "pytz                     2023.3\n",
      "pytz-deprecation-shim    0.1.0.post0\n",
      "pywaffle                 1.1.0\n",
      "PyWavelets               1.5.0\n",
      "pywin32                  306\n",
      "pywinpty                 2.0.10\n",
      "PyYAML                   6.0\n",
      "pyzmq                    25.0.2\n",
      "qtconsole                5.4.3\n",
      "QtPy                     2.3.1\n",
      "regex                    2023.10.3\n",
      "requests                 2.28.2\n",
      "rfc3339-validator        0.1.4\n",
      "rfc3986-validator        0.1.1\n",
      "rich                     13.4.1\n",
      "s3fs                     2023.4.0\n",
      "safetensors              0.4.1\n",
      "scikit-learn             1.2.2\n",
      "scipy                    1.10.1\n",
      "seaborn                  0.13.0\n",
      "Send2Trash               1.8.2\n",
      "setuptools               65.5.0\n",
      "simpy                    4.0.2\n",
      "six                      1.16.0\n",
      "smart-open               6.4.0\n",
      "smmap                    5.0.0\n",
      "sniffio                  1.3.0\n",
      "soupsieve                2.4.1\n",
      "spacy                    3.7.2\n",
      "spacy-legacy             3.0.12\n",
      "spacy-loggers            1.0.5\n",
      "squarify                 0.4.3\n",
      "srsly                    2.4.8\n",
      "stack-data               0.6.2\n",
      "streamlit                1.23.1\n",
      "sympy                    1.12\n",
      "tangled-up-in-unicode    0.2.0\n",
      "tenacity                 8.2.2\n",
      "terminado                0.17.1\n",
      "thinc                    8.2.1\n",
      "threadpoolctl            3.1.0\n",
      "tinycss2                 1.2.1\n",
      "tokenizers               0.15.0\n",
      "toml                     0.10.2\n",
      "toolz                    0.12.0\n",
      "torch                    2.1.1\n",
      "torchaudio               2.1.1\n",
      "torchvision              0.16.1\n",
      "tornado                  6.2\n",
      "tqdm                     4.66.1\n",
      "traitlets                5.9.0\n",
      "transformers             4.36.1\n",
      "typer                    0.9.0\n",
      "typing_extensions        4.6.3\n",
      "tzdata                   2023.3\n",
      "tzlocal                  4.3\n",
      "update-checker           0.18.0\n",
      "uri-template             1.2.0\n",
      "urllib3                  1.26.15\n",
      "validators               0.20.0\n",
      "visions                  0.7.4\n",
      "wasabi                   1.1.2\n",
      "watchdog                 3.0.0\n",
      "wcwidth                  0.2.6\n",
      "weasel                   0.3.4\n",
      "webcolors                1.13\n",
      "webencodings             0.5.1\n",
      "websocket-client         1.5.1\n",
      "Werkzeug                 2.3.3\n",
      "widgetsnbextension       4.0.7\n",
      "wordcloud                1.9.3\n",
      "wrapt                    1.15.0\n",
      "yarl                     1.8.2\n",
      "zipp                     3.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données depuis le fichier JSON\n",
    "dev_examples = \"C:\\\\Users\\\\Nitro\\Desktop\\\\tp3_2023\\\\data\\\\dev_examples.json\"\n",
    "with open(dev_examples, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Charger le tokenizer et le modèle préentraîné DistilBERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dynamiquement déterminer les classes à partir des données\n",
    "all_classes = set()\n",
    "for item in data:\n",
    "    if 'arguments' in item:\n",
    "        all_classes.update(item['arguments'].keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_SEQUENCE_LENGTH = 128  \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, classes, max_seq_length=MAX_SEQUENCE_LENGTH):\n",
    "        self.data = data\n",
    "        self.classes = classes\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        text = item['text']\n",
    "        labels_dict = {key: [-100] * self.max_seq_length for key in self.classes}\n",
    "\n",
    "        if 'arguments' in item:\n",
    "            for key, values in item['arguments'].items():\n",
    "                for value in values:\n",
    "                    start_idx = text.find(value)\n",
    "                    while start_idx != -1:\n",
    "                        end_idx = start_idx + len(value.split())\n",
    "                        # Tronquer ou remplir en fonction de la taille maximale de la séquence\n",
    "                        start_idx = min(start_idx, self.max_seq_length - 1)\n",
    "                        end_idx = min(end_idx, self.max_seq_length)\n",
    "                        labels_dict[key][start_idx:end_idx] = [1] * (end_idx - start_idx)\n",
    "                        start_idx = text.find(value, start_idx + 1)\n",
    "\n",
    "        # Tronquer ou remplir la séquence des étiquettes\n",
    "        padded_labels = []\n",
    "        for key in self.classes:\n",
    "            label = labels_dict[key][:self.max_seq_length]\n",
    "            padded_labels.append(label)\n",
    "\n",
    "        labels = torch.LongTensor(padded_labels)\n",
    "\n",
    "        return {'text': text, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données pour l'entraînement\n",
    "\n",
    "train_dataset = CustomDataset(train_data, all_classes)\n",
    "test_dataset = CustomDataset(test_data, all_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définir les paramètres d'entraînement\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DistilBertForTokenClassification.from_pretrained('distilbert-base-uncased', num_labels=len(all_classes))\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entraîner le modèle\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
    "        labels = {key: torch.tensor(value) for key, value in batch['labels'].items()}\n",
    "        inputs = {**inputs, **labels}\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer le modèle\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in test_dataset:\n",
    "    inputs = tokenizer(item['text'], return_tensors='pt', padding=True, truncation=True)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    predicted_labels = torch.argmax(outputs.logits, dim=2).cpu().numpy()\n",
    "    true_labels = {key: torch.tensor(value) for key, value in item['labels'].items()}\n",
    "    \n",
    "    for key, true_label in true_labels.items():\n",
    "        mask = true_label != -100\n",
    "        predicted_label = predicted_labels[0, mask]\n",
    "        true_label = true_label[mask]\n",
    "        y_true.extend(true_label.cpu().numpy())\n",
    "        y_pred.extend(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Calculer les scores\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "classification_rep = classification_report(y_true, y_pred)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
